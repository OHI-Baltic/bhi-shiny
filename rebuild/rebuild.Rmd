---
title: "Rebuild Shiny Dash"
output: html_document
---

```{r setup}
library(magrittr)
library(readr)
library(stringr)
library(dplyr)
library(tidyr)
library(sp)

assess_year <- 2019
bhi_version <- "v2019"
scenario_folder <- "baltic2019draft"

dir_main <- here::here()
if(length(grep("dashboard", dir_main, value = TRUE)) == 0){
  dir_main <- here::here("dashboard")
}

## these urls should connect to the most recent versions of everything
gh_api_bhiprep <- "https://api.github.com/repos/OHI-Science/bhi-prep/git/trees/master?recursive=1"
gh_raw_bhiprep <- "https://raw.githubusercontent.com/OHI-Science/bhi-prep/master/"
gh_raw_bhi <- "https://raw.githubusercontent.com/OHI-Science/bhi/master/"

source(here::here("rebuild", "rebuilding.R"))
```

<br>

## Get Most-Recent Data for Dashboard

```{r extract other relevant data from bhiprep github repo and write to data folder}
## assessment raw datasets metadata for data layers tables
data_info <- make_data_table(gh_raw_bhiprep, bhi_version)
write_csv(data_info, file.path(dir_main, "data", "data_info.csv"))

## 
```


```{r extract scores data from bhi github repo}
## assessment scores
bhiscores <- read_csv(paste0(gh_raw_bhi, "/scores.csv"), col_types = cols())

## check if layers in bhi-prep repo match those registered in bhi/layers.csv
## if not scores.csv may need to be recalculated, but could be extra layers were calculated but not used
ghlayers <- sort(list_prep_layers(gh_api_bhiprep))
lyrcsvfiles <- sort(readr::read_csv(paste0(gh_raw_bhi, "/layers.csv"))$filename)
all(lyrcsvfiles %in% paste0(ghlayers, ".csv"))
 
## need year column
## save data to dashboard data folder
bhiscores %>% 
  select(goal, dimension, region_id, score) %>% 
  mutate(year = ifelse("year" %in% names(bhiscores), year, assess_year))
```

<br>

## Configuration

```{r make sure everything is synced with main bhi repos}
```

<br>

## Global Datasets

```{r spatial data wrangling}
## copy over original shapefiles wherever they are saved, currently BHI_share...
## make lower resolution files for visualization, don't need same high resolution as for analysis
## also reproject to EPSG:4326 
## Leaflet expects point/line/shape data to be specified in lat/long using WGS 84 (a.k.a. EPSG:4326)
## https://rstudio.github.io/leaflet/projections.html
## save as rds files

## shapefiles currently saved at
dir_shp <- file.path(dirname(here::here()), "bhi-data", "Shapefiles")

## regions shapefile:
if(!file.exists(file.path(dir_main, "data", "regions.rds"))){
  
  bhi_rgns_shp <- sf::st_read(file.path(dir_shp, "BHI_shapefile")) %>%
    dplyr::mutate(Subbasin = as.character(Subbasin)) %>%
    dplyr::mutate(Subbasin = ifelse(
      ## NEED TO FIX THIS TYPO!!!
      Subbasin == "Bothian Sea", 
      "Bothnian Sea", Subbasin
    )) %>% 
    dplyr::mutate(Subbasin = ifelse(
      Subbasin == "Aland Sea" & rgn_key == "FIN", 
      "Archipelago Sea", Subbasin
    )) %>% 
    ## transform to EPSG:4326 crs
    sf::st_transform(crs = 4326)
  
  ## spatial rather than simple features...
  bhi_rgns_shp_simp <- rmapshaper::ms_simplify(input = bhi_rgns_shp)
  sf::as_Spatial(bhi_rgns_shp_simp) %>% 
    saveRDS(file.path(dir_main, "data", "regions.rds"))
  
} else(
  message(
    "regions.rds already exists. if you really want to replace it, manually select/run relevant lines above"
  )
)

## subbasins shapefile:
if(!file.exists(file.path(dir_main, "data", "subbasins.rds"))){
  
  subbasins_shp <- sf::st_read(file.path(dir_shp, "HELCOM_subbasins_holasbasins")) %>% 
    ## transform to EPSG:4326 crs
    sf::st_transform(crs = 4326) %>% 
    mutate(subbasin_id = 500 + as.numeric(substr(HELCOM_ID, 5, 7))) %>% 
    select(subbasin_id, helcom_id = HELCOM_ID, subbasin_area_km2 = AreaKM2, Name)

  ## spatial rather than simple features...
  subbasins_shp_simp <- rmapshaper::ms_simplify(input = subbasins_shp) 
  sf::as_Spatial(subbasins_shp_simp) %>% 
    saveRDS(file.path(dir_main, "data", "subbasins.rds"))
  
} else(
  message(
    "subbasins.rds already exists. if you really want to replace it, manually select/run relevant lines above"
  )
)

## marine protected areas shapefile:
if(!file.exists(file.path(dir_main, "data", "mpas.rds"))){

  mpa_shp <- sf::st_read(file.path(dir_shp, "HELCOM_MPAs"))

  ## spatial rather than simple features...
  ## transform to EPSG:3857 crs
  mpa_shp_simp <- rmapshaper::ms_simplify(input = mpa_shp) %>%
    sf::st_transform(crs = 4326)
  sf::as_Spatial(mpa_shp_simp) %>%
    saveRDS(file.path(dir_main, "data", "mpas.rds"))

} else(
  message(
    "mpas.rds already exists. if you really want to replace it, manually select/run relevant lines above"
  )
)

## check regions and subbasins dataframes,
## load also for next step-- creating flowerplots
regions_df <- readr::read_csv(file.path(dir_main, "data", "regions.csv"))
subbasins_df <- readr::read_csv(file.path(dir_main, "data", "basins.csv"))
```

<br>

## Make Flowerplots

```{r create all the flowerplots ahead of time because its slow}
source(here::here("rebuild", "flowerplot.R"))
source(file.path(dir_main, "R", "theme.R"))

flower_data <- readr::read_csv(file.path(dir_main, "data", "scores.csv"))

## need approx fish vs mariculture contribution to food provision
## read in intermediate layer saved from fp scores
fp_weights <- read_csv(paste0(gh_raw_bhi, scenario_folder, "/intermediate", "/wildcaught_weight.csv")) %>% 
  rename(value = prop_wildcaught)


## MAKE FLOWERPLOTS ----
make_flower_plot(
  rgn_scores = flower_data,
  rgns = c(0, 1:42, 501:517),
  plot_year = max(flower_data$year),
  dim = "score",
  color_pal = NA,
  color_by = "goal",
  include_ranges = TRUE, 
  labels = "arc",
  fis_mar_petals = fp_weights
)
```

<br>

## Revise select-input UI menus

```{r recreate UI select menus for additional figures on goal pages}
## select variable menu options for timeseries plots, rough outline...
goal_tsplot_options <- function(goal_code, datalyrscsv){
  
  optns_df <- datalyrscsv %>% 
    filter(str_detect(show_for_goals, goal_code), !is.na(plot_type)) %>% 
    select(full_layer_name, categories, data_filename, plot_type) %>% 
    mutate(categories = stringr::str_split(categories, "\\|")) %>% 
    tidyr::unnest(cols = c(categories)) %>% 
    mutate(data_filename = ifelse(
      is.na(categories), 
      stringr::str_replace(data_filename, "\\.csv", ""),
      stringr::str_replace(data_filename, "\\.csv", sprintf("_%s", categories))
    )) %>% 
    mutate(optns = ifelse(
      is.na(categories),
      sprintf("`%s` = \\\"%s\\\"", full_layer_name, data_filename),
      sprintf("`%s %s` = \\\"%s\\\"", str_to_sentence(categories), full_layer_name, data_filename)
    ))

  return(optns_df)
}
optns_df <- goal_tsplot_options("FIS", readr::read_csv(file.path(dir_main, "data", "datalayers.csv")))
cat(optns_df$optns, sep = "\", \n \"")
```

<br>

## Review and Update Text

```{r review and update text}
## check information in goals e.g. contaminants
source(here::here("rebuild", "shinytext.R"))
filter(shinytext, goal == "CON")
## to edit text, make changes in shinytext.R script



## pressures links section
prs_links <- prs_matrix %>% 
  left_join(
    data.frame(
      Pressure = prs_matrix$Pressure,
      folder = c(
        "invasive_spp", "climate_change", "climate_change", "oxygen_debt",
        "illegal_oil", "bottom_trawling", "atmos_con", "atmos_con", 
        "nutrient_load", "nutrient_load", "pressure_secchi", "wgi_social"
      ),
      doc = c(
        "invasive_spp_prep", "climate_change_prep", "climate_change_prep", "oxygen_debt_pressure_prep",
        "illegal_oil_prep", "bottom_trawling_prep", "atmos_con_prep", "atmos_con_prep",
        "nutrient_load_prep", "nutrient_load_prep", "pressure_secchi_prep", "wgi_social_prep"
      )
    ),
    by = "Pressure"
  ) %>% 
  mutate(url_suffix = sprintf("blob/master/prep/pressures/%s/%s/%s.md", folder, bhi_version, doc))

prs_titles <- vector()
for(i in 1:nrow(prs_links)){
  prs_titles <- c(
    prs_titles, 
    read_lines(sprintf("%s/prep/pressures/%s/%s/%s.md", gh_raw_bhiprep, prs_links$folder[i], bhi_version, prs_links$doc[i]))[1]
  )
}
prs_links <- cbind(prs_links, preptitle = prs_titles)

prs_links_txt <- function(goalname){
  df <- prs_links %>% 
    filter(!is.na(!!!syms(goalname))) %>% 
    distinct(url_suffix, preptitle)
  for(i in 1:nrow(df)){
    cat(paste0(
      "h5(strong(a(\n \t paste('\\n', '", 
      df$preptitle[i], 
      "'),\n \t href = sprintf('%s/",  
      df$url_suffix[i], 
      "', gh_prep), \n \t target = '_blank'\n ))), \n"
    ))
  }
}

prs_links_txt("Fisheries")
```

<br>

## Update/Repair Links

```{r update links to dataprep documents}
```

```{r check for any broken links}
```

