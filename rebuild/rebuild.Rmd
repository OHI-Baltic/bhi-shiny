---
title: "Rebuild Shiny Dash"
output: html_document
---

```{r setup}
library(magrittr)
library(readr)
library(stringr)
library(dplyr)
library(tidyr)
library(sp)
library(RSQLite)
library(DBI)


assess_year <- 2019
bhi_version <- "v2019"
scenario_folder <- "baltic2019draft"

dir_main <- here::here()
if(length(grep("dashboard", dir_main, value = TRUE)) == 0){
  dir_main <- here::here("dashboard")
}

## these urls should connect to the most recent versions of everything
gh_api_bhiprep <- "https://api.github.com/repos/OHI-Science/bhi-prep/git/trees/master?recursive=1"
gh_raw_bhiprep <- "https://raw.githubusercontent.com/OHI-Science/bhi-prep/master/"
gh_raw_bhi <- "https://raw.githubusercontent.com/OHI-Science/bhi/master/"

source(here::here("rebuild", "rebuilding.R"))
```

<br>

## Make Database

```{r creating or recreating bhi database for shinyapp}
## creating bhi database structure ----

## in R console:
bhidbconn <- dbConnect(SQLite(), dbname = "dashboard/data/bhi.db")
sql <- read_lines("rebuild/bhidb.sql") %>% 
  str_remove("\t") %>% 
  paste(collapse = "") %>% 
  str_split("(?<=;)") %>% 
  unlist()
for(s in sql[str_length(sql) > 1]){
  dbExecute(bhidbconn, s)
}
## in terminal:
## cd dashboard/data
## pwd
## sqlite3 bhi.db
## .read bhidb.sql
## .schema
## .exit


## static database tables, create once in db ----
goals <- read_csv(sprintf("%s/%s/conf/goals.csv", gh_raw_bhi, scenario_folder)) %>% 
  select(goal_name = goal, name, description)

flowerConf <- read_csv(sprintf("%s/%s/conf/goals.csv", gh_raw_bhi, scenario_folder)) %>% 
  select(goal, parent, name_flower, petalweight = weight, order_hierarchy)

regions <- read_csv(sprintf("%s/%s/layers/rgns_complete.csv", gh_raw_bhi, scenario_folder)) %>% 
  select(region_id, subbasin, eez, region_name, area_km2 = region_area_km2, region_order)

subbasins <- read_csv(sprintf("%s/%s/layers/rgns_complete.csv", gh_raw_bhi, scenario_folder)) %>% 
  distinct(helcom_id, region_id = subbasin_id, subbasin, area_km2 = subbasin_area_km2, subbasin_order)


pressures <- read_csv(sprintf("%s%s/conf/goals.csv", gh_raw_bhi, scenario_folder)) %>% 
  filter(!is.na(preindex_function)) %>%
  select(goal, goal_name = name) %>%
  left_join(read_csv(sprintf("%s%s/conf/pressures_matrix.csv", gh_raw_bhi, scenario_folder))) %>%
  select(-goal, -element, -element_name) %>%
  tidyr::pivot_longer(cols = sp_invasives:ss_wgi, names_to = "layer", values_to = "weight")

resilience <- read_csv(sprintf("%s%s/conf/goals.csv", gh_raw_bhi, scenario_folder)) %>% 
  filter(!is.na(preindex_function)) %>%
  select(goal, goal_name = name) %>%
  left_join(read_csv(sprintf("%s%s/conf/resilience_matrix.csv", gh_raw_bhi, scenario_folder))) %>%
  select(-goal, -element) %>% 
  tidyr::pivot_longer(cols = wgi_all:res_reg_pop, names_to = "layer", values_to = "weighted") %>%
  left_join(read_csv(sprintf("%s%s/conf/resilience_categories.csv", gh_raw_bhi, scenario_folder))) %>%
  mutate(weight = ifelse(is.na(weighted), NA, weight)) %>% 
  select(goal_name, layer, weight, category, category_type, subcategory)


for(tab in c(goals, flowerConf, regions, subbasins)){
  dbWriteTable(
    conn = bhidbconn,
    name = stringr::str_to_upper(tab),
    value = get(tab),
    row.names = FALSE,
    append = TRUE,
    binary = TRUE
  )
}
dbDisconnect(bhidbconn)
```

<br>

## Update Data

```{r data from bhiprep and bhi github repos}
## data sources ----
## assessment raw datasets metadata for data sources tables
dataSources <- make_data_table(gh_raw_bhiprep, bhi_version) %>% 
  distinct(goal = `Goal/Subgoal`, dataset = Dataset, description = Description, source = Source)


## assessment scores ----
scores <- read_csv(sprintf("%s%s/scores.csv", gh_raw_bhi, scenario_folder), col_types = cols())


## check if layers in bhi-prep repo match those registered in bhi/layers.csv
## if not scores.csv may need to be recalculated, 
## but also could be that extra layers were calculated but not used
ghlayers <- sort(list_prep_layers(gh_api_bhiprep))
lyrcsvfiles <- sort(readr::read_csv(paste0(gh_raw_bhi, "/layers.csv"))$filename)
all(lyrcsvfiles %in% paste0(ghlayers, ".csv"))
 
## need year column
## save data to dashboard database
indexScores <- scores %>% 
  mutate(year = ifelse("year" %in% names(bhiscores), year, assess_year)) %>% 
  select(region_id, dimension, goal, score, year)



## additional figures config info ----
## note: do not cache oauth access credentials between sessions
# library(googlesheets4)
# shinyfigssheet <- "https://docs.google.com/spreadsheets_url_replace_here"
# addfigsconf <- read_sheet(shinyfigssheet) %>%
#   select(show_for_goals:max_year) %>% 
#   filter()



## entering data in bhi database ----

## 1. connect to database
## 2. clean datasets when entering them into the database
## 3. disconnect from database

bhidbconn <- dbConnect(SQLite(), dbname = "dashboard/data/bhi.db")

for(tab in c("dataSources", "indexScores")){
# for(tab in c("dataSources", "indexScores", "additionalFigs")){
  dbWriteTable(
    conn = bhidbconn,
    name = stringr::str_to_title(tab),
    value = get(tab),
    row.names = FALSE,
    append = TRUE,
    binary = TRUE
  )
}
dbDisconnect(bhidbconn)
```

<br>

## Global Datasets

```{r spatial data wrangling}
## copy over original shapefiles wherever they are saved, currently BHI_share...
## make lower resolution files for visualization, don't need same high resolution as for analysis
## also reproject to EPSG:4326 
## Leaflet expects point/line/shape data to be specified in lat/long using WGS 84 (a.k.a. EPSG:4326)
## https://rstudio.github.io/leaflet/projections.html
## save as rds files

## shapefiles currently saved at
dir_shp <- file.path(dirname(here::here()), "bhi-data", "Shapefiles")

## regions shapefile:
if(!file.exists(file.path(dir_main, "data", "regions.rds"))){
  
  bhi_rgns_shp <- sf::st_read(file.path(dir_shp, "BHI_shapefile")) %>%
    dplyr::mutate(Subbasin = as.character(Subbasin)) %>%
    dplyr::mutate(Subbasin = ifelse(
      ## NEED TO FIX THIS TYPO!!!
      Subbasin == "Bothian Sea", 
      "Bothnian Sea", Subbasin
    )) %>% 
    dplyr::mutate(Subbasin = ifelse(
      Subbasin == "Aland Sea" & rgn_key == "FIN", 
      "Archipelago Sea", Subbasin
    )) %>% 
    ## transform to EPSG:4326 crs
    sf::st_transform(crs = 4326)
  
  ## spatial rather than simple features...
  bhi_rgns_shp_simp <- rmapshaper::ms_simplify(input = bhi_rgns_shp)
  sf::as_Spatial(bhi_rgns_shp_simp) %>% 
    saveRDS(file.path(dir_main, "data", "regions.rds"))
  
} else(
  message(
    "regions.rds already exists. if you really want to replace it, manually select/run relevant lines above"
  )
)

## subbasins shapefile:
if(!file.exists(file.path(dir_main, "data", "subbasins.rds"))){
  
  subbasins_shp <- sf::st_read(file.path(dir_shp, "HELCOM_subbasins_holasbasins")) %>% 
    ## transform to EPSG:4326 crs
    sf::st_transform(crs = 4326) %>% 
    mutate(subbasin_id = 500 + as.numeric(substr(HELCOM_ID, 5, 7))) %>% 
    select(subbasin_id, helcom_id = HELCOM_ID, subbasin_area_km2 = AreaKM2, Name)

  ## spatial rather than simple features...
  subbasins_shp_simp <- rmapshaper::ms_simplify(input = subbasins_shp) 
  sf::as_Spatial(subbasins_shp_simp) %>% 
    saveRDS(file.path(dir_main, "data", "subbasins.rds"))
  
} else(
  message(
    "subbasins.rds already exists. if you really want to replace it, manually select/run relevant lines above"
  )
)

## marine protected areas shapefile:
if(!file.exists(file.path(dir_main, "data", "mpas.rds"))){

  mpa_shp <- sf::st_read(file.path(dir_shp, "HELCOM_MPAs"))

  ## spatial rather than simple features...
  ## transform to EPSG:3857 crs
  mpa_shp_simp <- rmapshaper::ms_simplify(input = mpa_shp) %>%
    sf::st_transform(crs = 4326)
  sf::as_Spatial(mpa_shp_simp) %>%
    saveRDS(file.path(dir_main, "data", "mpas.rds"))

} else(
  message(
    "mpas.rds already exists. if you really want to replace it, manually select/run relevant lines above"
  )
)
```

<br>

## Make Flowerplots

```{r create all the flowerplots ahead of time because its slow}
source(here::here("rebuild", "flowerplot.R"))
source(file.path(dir_main, "R", "theme.R"))

bhidbconn <- dbConnect(SQLite(), dbname = "dashboard/data/bhi.db")
flower_data <- dbReadTable(bhidbconn, "IndexScores")

## need approx fish vs mariculture contribution to food provision
## read in intermediate layer saved from fp scores
fp_weights <- read_csv(paste0(gh_raw_bhi, scenario_folder, "/intermediate", "/wildcaught_weight.csv")) %>% 
  rename(value = prop_wildcaught)


## MAKE FLOWERPLOTS ----
make_flower_plot(
  rgn_scores = flower_data,
  rgns = c(0, 1:42, 501:517),
  plot_year = max(flower_data$year),
  dim = "score",
  color_pal = NA,
  color_by = "goal",
  include_ranges = TRUE, 
  labels = "arc",
  fis_mar_petals = fp_weights
)
```

<br>

## Revise select-input UI menus

```{r recreate UI select menus for additional figures on goal pages}
## select variable menu options for timeseries plots, rough outline...
goal_tsplot_options <- function(goal_code, datalyrscsv){
  
  optns_df <- datalyrscsv %>% 
    filter(str_detect(show_for_goals, goal_code), !is.na(plot_type)) %>% 
    select(full_layer_name, categories, data_filename, plot_type) %>% 
    mutate(categories = stringr::str_split(categories, "\\|")) %>% 
    tidyr::unnest(cols = c(categories)) %>% 
    mutate(data_filename = ifelse(
      is.na(categories), 
      stringr::str_replace(data_filename, "\\.csv", ""),
      stringr::str_replace(data_filename, "\\.csv", sprintf("_%s", categories))
    )) %>% 
    mutate(optns = ifelse(
      is.na(categories),
      sprintf("`%s` = \\\"%s\\\"", full_layer_name, data_filename),
      sprintf("`%s %s` = \\\"%s\\\"", str_to_sentence(categories), full_layer_name, data_filename)
    ))

  return(optns_df)
}
optns_df <- goal_tsplot_options("FIS", readr::read_csv(file.path(dir_main, "data", "datalayers.csv")))
cat(optns_df$optns, sep = "\", \n \"")
```

<br>

## Review and Update Text

```{r review and update text}
## check information in goals e.g. contaminants
source(here::here("rebuild", "shinytext.R"))
filter(shinytext, goal == "CON")
## to edit text, make changes in shinytext.R script



## pressures links section
prs_links <- prs_matrix %>% 
  left_join(
    data.frame(
      Pressure = prs_matrix$Pressure,
      folder = c(
        "invasive_spp", "climate_change", "climate_change", "oxygen_debt",
        "illegal_oil", "bottom_trawling", "atmos_con", "atmos_con", 
        "nutrient_load", "nutrient_load", "pressure_secchi", "wgi_social"
      ),
      doc = c(
        "invasive_spp_prep", "climate_change_prep", "climate_change_prep", "oxygen_debt_pressure_prep",
        "illegal_oil_prep", "bottom_trawling_prep", "atmos_con_prep", "atmos_con_prep",
        "nutrient_load_prep", "nutrient_load_prep", "pressure_secchi_prep", "wgi_social_prep"
      )
    ),
    by = "Pressure"
  ) %>% 
  mutate(url_suffix = sprintf("blob/master/prep/pressures/%s/%s/%s.md", folder, bhi_version, doc))

prs_titles <- vector()
for(i in 1:nrow(prs_links)){
  prs_titles <- c(
    prs_titles, 
    read_lines(sprintf("%s/prep/pressures/%s/%s/%s.md", gh_raw_bhiprep, prs_links$folder[i], bhi_version, prs_links$doc[i]))[1]
  )
}
prs_links <- cbind(prs_links, preptitle = prs_titles)

prs_links_txt <- function(goalname){
  df <- prs_links %>% 
    filter(!is.na(!!!syms(goalname))) %>% 
    distinct(url_suffix, preptitle)
  for(i in 1:nrow(df)){
    cat(paste0(
      "h5(a(\n \t paste('\\n', '", 
      df$preptitle[i], 
      "'),\n \t href = sprintf('%s/",  
      df$url_suffix[i], 
      "', gh_prep), \n \t target = '_blank'\n )), \n"
    ))
  }
}

prs_links_txt("Fisheries")
```

<br>

